{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5339aa3",
   "metadata": {},
   "source": [
    "# Unbalanced Data\n",
    "\n",
    "Unbalanced data is one of the most common stumbling block for new data science practioners.  This is because ultimately, sometimes, its about accepting failure.  On some worked problems you can get okay class separation, but most of the time, you are going to fail on imbalanced problems.  There are tools in few shot and zero shot learning that can help, but only on some classes of problems and only under certain constraints.  \n",
    "\n",
    "After going through undergrad and likely a masters or maybe even two, the feeling for most new practioners is that the suite of machine learning tools available today can solve any problem!  With the kernel tricks of SVMs, the highly non-linear universal approximators from tree based algorithms and from the mighty neural network, all problems must assuredly fall!  \n",
    "\n",
    "And yet, it turns out all these genius algorithms aren't always all that smart.  Sometimes, all the tricks in the world won't get you a good looking confusion matrix.  There are some things we can do, to be sure.  But even they may fail in some cases.\n",
    "\n",
    "Let's begin with a somewhat realistic data split, 90/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a5cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn.datasets import make_moons\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def ratio_func(y, multiplier, minority_class):\n",
    "    target_stats = Counter(y)\n",
    "    return {minority_class: int(multiplier * target_stats[minority_class])}\n",
    "\n",
    "X, y = make_moons(n_samples=4000, shuffle=True, noise=0.5, random_state=10)\n",
    "X = pd.DataFrame(X, columns=[\"feature 1\", \"feature 2\"])\n",
    "\n",
    "multiplier = 0.1\n",
    "X_resampled, y_resampled = make_imbalance(\n",
    "    X,\n",
    "    y,\n",
    "    sampling_strategy=ratio_func,\n",
    "    **{\"multiplier\": multiplier, \"minority_class\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197c4658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2000\n",
       "1     200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888585d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       505\n",
      "           1       0.61      0.24      0.35        45\n",
      "\n",
      "    accuracy                           0.93       550\n",
      "   macro avg       0.77      0.62      0.65       550\n",
      "weighted avg       0.91      0.93      0.91       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled)\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99bfa2",
   "metadata": {},
   "source": [
    "Ofph!  Not looking great.  That class 1 recall _sucks_.  Let's see if we can do better with a Linear SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c71f350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       496\n",
      "           1       0.58      0.20      0.30        54\n",
      "\n",
      "    accuracy                           0.91       550\n",
      "   macro avg       0.75      0.59      0.63       550\n",
      "weighted avg       0.89      0.91      0.89       550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled)\n",
    "l_svc = LinearSVC()\n",
    "l_svc.fit(X_train, y_train)\n",
    "pred = l_svc.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09799dd3",
   "metadata": {},
   "source": [
    "Not really any better!  Okay, let's try some hyperparameter tuning.  Because we are using cross validation we can stick with train and test.  If we didn't use CV then we'd need an explicit validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398615f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       496\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.90       550\n",
      "   macro avg       0.45      0.50      0.47       550\n",
      "weighted avg       0.81      0.90      0.86       550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]},\n",
    "]\n",
    "svc = SVC()\n",
    "grid_search = GridSearchCV(svc, tuned_parameters)\n",
    "grid_search.fit(X_train, y_train)\n",
    "svc = SVC(**grid_search.best_params_)\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca43522",
   "metadata": {},
   "source": [
    "Well that was somehow worse!  Ofph.  Let's see what happens if we try doing stratified train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a1ffd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       500\n",
      "           1       0.71      0.24      0.36        50\n",
      "\n",
      "    accuracy                           0.92       550\n",
      "   macro avg       0.82      0.61      0.66       550\n",
      "weighted avg       0.91      0.92      0.90       550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, stratify=y_resampled)\n",
    "l_svc = LinearSVC()\n",
    "l_svc.fit(X_train, y_train)\n",
    "pred = l_svc.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6322d30",
   "metadata": {},
   "source": [
    "Okay!  Finally some slight improvement!  So it looks like rebalancing based on the data _may_ be what we need!  Time to bring in imbalance-learn to see if we can do any better.\n",
    "\n",
    "Rebalancing means either over sampling the minority class or under sampling the majority class to make the classification more balanced.  Take heed!  You can only rebalance on the training data though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22c8cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method Random Under Sampler\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85       500\n",
      "           1       0.25      0.80      0.38        50\n",
      "\n",
      "    accuracy                           0.76       550\n",
      "   macro avg       0.61      0.78      0.61       550\n",
      "weighted avg       0.91      0.76      0.81       550\n",
      "\n",
      "method Tomek Links\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       500\n",
      "           1       0.68      0.30      0.42        50\n",
      "\n",
      "    accuracy                           0.92       550\n",
      "   macro avg       0.81      0.64      0.69       550\n",
      "weighted avg       0.91      0.92      0.91       550\n",
      "\n",
      "method Edited Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       500\n",
      "           1       0.47      0.46      0.46        50\n",
      "\n",
      "    accuracy                           0.90       550\n",
      "   macro avg       0.71      0.70      0.71       550\n",
      "weighted avg       0.90      0.90      0.90       550\n",
      "\n",
      "method Repeated Edited Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       500\n",
      "           1       0.44      0.56      0.50        50\n",
      "\n",
      "    accuracy                           0.90       550\n",
      "   macro avg       0.70      0.75      0.72       550\n",
      "weighted avg       0.91      0.90      0.90       550\n",
      "\n",
      "method One Sided Selection\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       500\n",
      "           1       0.68      0.30      0.42        50\n",
      "\n",
      "    accuracy                           0.92       550\n",
      "   macro avg       0.81      0.64      0.69       550\n",
      "weighted avg       0.91      0.92      0.91       550\n",
      "\n",
      "method Neighbourhood Cleaning Rule\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       500\n",
      "           1       0.46      0.48      0.47        50\n",
      "\n",
      "    accuracy                           0.90       550\n",
      "   macro avg       0.70      0.71      0.71       550\n",
      "weighted avg       0.90      0.90      0.90       550\n",
      "\n",
      "method Instance Hardness Threshold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.91       500\n",
      "           1       0.32      0.68      0.43        50\n",
      "\n",
      "    accuracy                           0.84       550\n",
      "   macro avg       0.64      0.77      0.67       550\n",
      "weighted avg       0.91      0.84      0.86       550\n",
      "\n",
      "method Near Miss\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       500\n",
      "           1       0.34      0.62      0.44        50\n",
      "\n",
      "    accuracy                           0.86       550\n",
      "   macro avg       0.65      0.75      0.68       550\n",
      "weighted avg       0.90      0.86      0.87       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    ClusterCentroids,\n",
    "    TomekLinks,\n",
    "    EditedNearestNeighbours,\n",
    "    OneSidedSelection,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    InstanceHardnessThreshold,\n",
    "    NearMiss,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    ")\n",
    "\n",
    "def rebalance_learn(X_train, y_train, random_state: int = 123):\n",
    "    rus = RandomUnderSampler(random_state=random_state)\n",
    "    X_train_ru, y_train_ru = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    tl = TomekLinks()\n",
    "    X_train_tl, y_train_tl = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "    enn = EditedNearestNeighbours()\n",
    "    X_train_enn, y_train_enn = enn.fit_resample(X_train, y_train)\n",
    "\n",
    "    r_enn = RepeatedEditedNearestNeighbours()\n",
    "    X_train_r_enn, y_train_r_enn = r_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "    oss = OneSidedSelection(random_state=random_state)\n",
    "    X_train_oss, y_train_oss = oss.fit_resample(X_train, y_train)\n",
    "\n",
    "    ncr = NeighbourhoodCleaningRule()\n",
    "    X_train_ncr, y_train_ncr = ncr.fit_resample(X_train, y_train)\n",
    "\n",
    "    iht = InstanceHardnessThreshold(random_state=random_state)\n",
    "    X_train_iht, y_train_iht = iht.fit_resample(X_train, y_train)\n",
    "\n",
    "    nm = NearMiss()\n",
    "    X_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "    return [\n",
    "        (X_train_ru, y_train_ru),\n",
    "        (X_train_tl, y_train_tl),\n",
    "        (X_train_enn, y_train_enn),\n",
    "        (X_train_r_enn, y_train_r_enn),\n",
    "        (X_train_oss, y_train_oss),\n",
    "        (X_train_ncr, y_train_ncr),\n",
    "        (X_train_iht, y_train_iht),\n",
    "        (X_train_nm, y_train_nm),\n",
    "    ]\n",
    "\n",
    "samplers = [\n",
    "    \"Random Under Sampler\",\n",
    "    \"Tomek Links\",\n",
    "    \"Edited Nearest Neighbors\",\n",
    "    \"Repeated Edited Nearest Neighbors\",\n",
    "    \"One Sided Selection\",\n",
    "    \"Neighbourhood Cleaning Rule\",\n",
    "    \"Instance Hardness Threshold\",\n",
    "    \"Near Miss\"\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, stratify=y_resampled)\n",
    "rebalanced_datasets = rebalance_learn(X_train, y_train, random_state = 123)\n",
    "for index, rebalanced_data in enumerate(rebalanced_datasets):\n",
    "    method = samplers[index]\n",
    "    X_train, y_train = rebalanced_data\n",
    "    l_svc = LinearSVC()\n",
    "    l_svc.fit(X_train, y_train)\n",
    "    pred = l_svc.predict(X_test)\n",
    "    print(\"method\", method)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65555362",
   "metadata": {},
   "source": [
    "In summary, we do better than before with rebalancing!  But still not great.  And that's basically the point.  You can get to a place with rebalancing.  But you can't get all the way if your data is super unbalanced.   We could still try more hyperparameter tuning and more model classes.  Additionally, we can try anamoly detection methods:\n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html - mahalanobis distances\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html - isolation forests\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html - one class svm\n",
    "\n",
    "If none of that works, then it's onto few shot and zero shot learning methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
