{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Basics\n",
    "\n",
    "Probably the biggest shift when getting started with data science is the syntax of numpy and pandas because it differs so much from other programming paradigms.  In this section we will walk through some numpy basics:\n",
    "\n",
    "* why numpy?\n",
    "* introduction to tensors\n",
    "* numpy shapes\n",
    "* numpy slicing\n",
    "* numpy querying\n",
    "* linear algebra in numpy\n",
    "\n",
    "## Why Numpy?\n",
    "\n",
    "Technically, anything you can do in numpy you can do in plain old python.  And arguably the syntax will be easier to understand, that is, unless you use numpy as it is intended.  Numpy _can_ be used for all the basic stuff that you'll find most of the examples for on the internet.  But it's really _intended_ to be used for a new paradigm of programming.  One that's caught on in the statistical and deep learning communities (which have at least some overlap).  \n",
    "\n",
    "Numpy's api and computation is optimized for the manipulation of algebraic structures.  You can use it to do most of the computation that you can do with vanilla Python, or any other programming lanugage.  But you probably shouldn't.  We can think of the numpy api as sort of a directed language.  It's not quiet that, because numpy is mostly \"about\" syntax change.  You are thinking about the world from a difference lense.  But I digress.\n",
    "\n",
    "Here are just a few of the benefits of numpy:\n",
    "\n",
    "* incredible speed - numpy is _much_ faster than vanilla python (it can even outperform Java sometimes)\n",
    "* a beautiful and well organized api\n",
    "* tons of utility functions\n",
    "* amazing documentation\n",
    "* it's completely free (whaaaaat)\n",
    "\n",
    "To really understand numpy and the power it brings, we need to understand tensors.  Because without them, numpy honestly doesn't make much sense, at least at first.  And even once you start to get used to the syntax, without the mental model of a tensor, you'll completely miss the point of using it.\n",
    "\n",
    "## Tensors\n",
    "\n",
    "Tensors are some of the most powerful objects around.  In fact, this book is basically just a \"how do I use tensors\" most of the time.  The chapter on linear regression?  That's just about tensors.  The chapter on classification?  More applications of tensors.  Much of machine learning is built on tensors.  Specifically, on matrices.  Because I define the matrix in another chapter, I won't go into a ton of detail about what they are, or how to use them.  \n",
    "\n",
    "Basically, tensors are the generalization of matrices.  Examples of tensors include:\n",
    "\n",
    "* scalars\n",
    "* vectors\n",
    "* matrices\n",
    "* order-3 tensors and higher\n",
    "\n",
    "A scalar is an order zero tensor - because it's just a single number, like say the number `5`.  A vector is a one dimensional collection of numbers representing data or an equation, like: \n",
    "\n",
    "$$ \\begin{pmatrix}\n",
    "1  \\\\\n",
    "4  \\\\\n",
    "7 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "A matrix is a two dimensional collect of numbers representing a system of equations, like:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "An order three tensor looks like a data cube.  There is no easy way to show such a cube in latex, so you'll have to imagine this to some extent:\n",
    "\n",
    "$$ A_{1} = \n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$ A_{2} = \n",
    "\\begin{pmatrix}\n",
    "3 & 2 & 3 \\\\\n",
    "7 & 6 & 6 \\\\\n",
    "7 & 2 & 9\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$ A_{3} = \n",
    "\\begin{pmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "7 & 6 & 4 \\\\\n",
    "6 & 2 & 19\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Now imagine $A_{1}, A_{2}, A_{3}$ as one object.  This is an order three tensor.  It has three axes - $(i,j,k)$ and you can specify elements across these three axes.  So $(0,0,0) = 1$, $(1,0,0) = 4$, and $(3,0,3) = 6$.  Here the i is the row index, j is the column index and k is the matrix index.  You can also do this for order 4 and up to n, where n is any finite natural number you like.  Why might you want to ever do this in practice?  It turns out there are actually a ton of good reasons.\n",
    "\n",
    "Here are just two of them:\n",
    "\n",
    "1. Let's say you want to model multivariate timeseries geospatial data.  This is naturally an order 4 tensor.  The first two dimensions will be each snapshot of multivariate data.  Your third dimension will be that snapshot overtime.  And your forth will be over time and different geographies.  Thinking about it this way is useful for capturing shared weights between time and geographies.  How you model your data matters.  And by ignoring the time or geospatial components of your data, you might lose some important information.\n",
    "\n",
    "2. You can get a performance boost, statistically speaking.  As this paper shows: https://arxiv.org/pdf/1811.06569.pdf you can get a decent accuracy boost by treating your neural network as a higher order tensor.\n",
    "\n",
    "## Numpy Shapes\n",
    "\n",
    "Now that you know what a tensor is, the syntax of numpy will seem obvious and straight forward.  Let's start by showing how to represent each of the tensors we've discussed thus far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# order 0 tensor\n",
    "import numpy as np\n",
    "\n",
    "scalar = np.array([1])\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may think we've done nothing new here.  But actually we have!  For starters, numpy attaches types to anything passed into it.  And it does this _implicitly_.  You never have to name the types.  That by itself would be a feat of engineering prowess.  Let's see what I'm talking about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dtype` property tells us what kind of data is in our tensor.  Since there are mathematical consequences to what's in our tensor, it's best to define one type per tensor.  Usually floats are the most flexible.  Of course, you can define a tensor with multiple types.  But for any serious mathematical computation, this is discouraged.  However, there are lots of programming instances when defining multiple types in a data structure is useful and important, which is why this paradigm is supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', '1'], dtype='<U5')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen an order 0 tensor and an order 1 tensor, by accident, let's define another order 1 tensor, called a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 7]\n"
     ]
    }
   ],
   "source": [
    "vector = np.array([1, 4, 7])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note here:\n",
    "\n",
    "1. a vector is a collection of scalars.\n",
    "2. a vector represents a mathematical object, not just an array.\n",
    "\n",
    "Because this is a mathematical object, we can do things like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_one = np.array([1, 4, 7])\n",
    "vector_two = np.array([2, 4, 6])\n",
    "\n",
    "np.matmul(vector_one, vector_two.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've ever taken a linear algebra course the answer that's produced will seem surprising.  That's because technically numpy defaults to an array of scalars for a one dimensional array passed to the `np.array` method, rather than a vector.  The difference here is important.\n",
    "\n",
    "Because algebraic objects are defined in part by the algebraic operators attached to them, this detail matters.  Specifically, here the \"multiplication\" attached to our vectors is the inner product in this case.  If we want the outer product, which is what most folks who have taken linear algebra would expect, then we need to tell numpy that we are working with tensors or order 1 aka vectors and not a collection of scalars.\n",
    "\n",
    "We do that by using the `reshape` method a powerful tool that will allow us to represent tensors of any order we like.  But first let's start with the basics of turning a collection of scalars into an order 1 tensor, aka a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector one:\n",
      "[[1]\n",
      " [4]\n",
      " [7]]\n",
      "vector two: [[2 4 6]]\n",
      "result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2,  4,  6],\n",
       "       [ 8, 16, 24],\n",
       "       [14, 28, 42]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_one = np.array([1, 4, 7])\n",
    "vector_two = np.array([2, 4, 6])\n",
    "\n",
    "vector_one = vector_one.reshape(3, 1)\n",
    "vector_two = vector_two.reshape(1, 3)\n",
    "print(\"vector one:\")\n",
    "print(vector_one)\n",
    "print(\"vector two:\", vector_two)\n",
    "print(\"result:\")\n",
    "np.matmul(vector_one, vector_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reshaping our vectors to the appropriate shapes, we were able to produce a matrix!  This is a general fact of linear algebra - you can get a matrix by applying a matrix multiplication (`matmul`), also known as the outer product, to two vectors.  This \"trick\" of taking two lower dimensional tensors to create a higher order one will actually work for _any_ tensor we like.  If we want to recover an order 3 tensor we simply need to multiply a matrix by a vector.  That's because the order is additive, by tensor product!  Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5 10 15]\n",
      "  [ 1  2  3]\n",
      "  [ 3  6  9]]\n",
      "\n",
      " [[ 1  2  3]\n",
      "  [ 1  2  3]\n",
      "  [ 1  2  3]]\n",
      "\n",
      " [[ 1  2  3]\n",
      "  [ 2  4  6]\n",
      "  [ 1  2  3]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[ 5, 1 ,3], \n",
    "              [ 1, 1 ,1], \n",
    "              [ 1, 2 ,1]])\n",
    "b = np.array([1, 2, 3])\n",
    "print(np.tensordot(a, b, axes=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `a` is a matrix, `b` is a tensor.  And by taking the tensor product of the two of them, we recover an order 3 tensor!  Notice we have to provide an axes or the `tensorproduct` method.  This is because a tensor product can be defined on any order.  We've already seen an order 1 tensor product, the inner product.  And we've seen an order 2 tensor product, the outer product.  In higher spaces, we generally refer to the product as simply the tensor product where the order comes from context.  However, please take care to be clear about the shapes of your tensors, otherwise you'll end up doing the _wrong multiplication_.  \n",
    "\n",
    "I'll leave as an exercise creating tensors of order 4, 5, and 6.  Happy multiplying!\n",
    "\n",
    "## Numpy Slicing\n",
    "\n",
    "Now that we've seen how to create our tensors the next step is to be able to index into them.  The number of axes that you specify will determine how deep a slice you get back.  For instance, if you are working with an order 3 tensor and you specify one axes, you'll get back a matrix.  If you specify two, you'll get back a vector.  And if you specify all three you'll get back a scalar.  Let's see some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 1, 3],\n",
       "       [1, 1, 1],\n",
       "       [1, 2, 1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting back a matrix\n",
    "a = np.array([[ 5, 1 ,3], \n",
    "              [ 1, 1 ,1], \n",
    "              [ 1, 2 ,1]])\n",
    "b = np.array([1, 2, 3])\n",
    "order_3_tensor = np.tensordot(a, b, axes=0)\n",
    "\n",
    "order_3_tensor[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy syntax for slicing may seem somewhat familar, but maybe not.  In vanilla Python you can choose a number of elements by slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing = list(range(20))\n",
    "\n",
    "print(listing[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `[:]` just gives back a \"slice\" that's equal to the whole array, because we didn't specify any start an end.  But if say we just wanted the last 3 elements we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "listing = list(range(20))\n",
    "\n",
    "print(listing[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can fully specify the start and end as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "listing = list(range(20))\n",
    "\n",
    "print(listing[5:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, that's only for a one dimensional array.  In numpy, we are dealing with _many_ dimensions, which is why the syntax looks different.  In the example above we had:\n",
    "\n",
    "`order_3_tensor[:, :, 0]`\n",
    "\n",
    "The first axis is selected completely so like with vanilla Python lists, we simply do `[:` for the whole thing.  Next we get the entire second axis so we have: `[:, :`.  And finally, we just want the first \"element\" along the third axis: `[:, :, 0]`.  At first, this syntax seems confusing to everyone.  But once it clicks, by understanding numpy arrays as tensors, then everything in the syntax becomes _obvious_.\n",
    "\n",
    "Let's move onto our second example.  This time we'll get back just a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting back a vector\n",
    "a = np.array([[ 5, 1 ,3], \n",
    "              [ 1, 1 ,1], \n",
    "              [ 1, 2 ,1]])\n",
    "b = np.array([1, 2, 3])\n",
    "order_3_tensor = np.tensordot(a, b, axes=0)\n",
    "\n",
    "order_3_tensor[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we've specified _two_ axes and therefore, we get back an order 1 tensor.  Now, let's move onto the final example and get back just a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting back a scalar\n",
    "a = np.array([[ 5, 1 ,3], \n",
    "              [ 1, 1 ,1], \n",
    "              [ 1, 2 ,1]])\n",
    "b = np.array([1, 2, 3])\n",
    "order_3_tensor = np.tensordot(a, b, axes=0)\n",
    "\n",
    "order_3_tensor[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to notice, the first order 2 slice of our order 3 tensor is just the matrix `a`.  This is because the first element in our vector `b` is a 1.  I'll leave as an exercise, to see if you can write a slice that recovers the first row of matrix a.  Your answer should look like this:\n",
    "\n",
    "`[5, 1, 3]`\n",
    "\n",
    "Here is the starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[ 5, 1 ,3], \n",
    "              [ 1, 1 ,1], \n",
    "              [ 1, 2 ,1]])\n",
    "b = np.array([1, 2, 3])\n",
    "order_3_tensor = np.tensordot(a, b, axes=0)\n",
    "\n",
    "# put in your slices here\n",
    "#order_3_tensor[, , ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there is more than one way to recover the row in question.\n",
    "\n",
    "## Numpy Querying\n",
    "\n",
    "So far we've looked at the mathematical advantages of numpy.  There was another claim I made, that numpy is blazing fast.  And I wasn't kidding.  Compare numpy with vanilla python on _many_ operations and you'll see it's power.  That's because numpy is written in C with it's api specified in Python.  This means it can take advantage of the high level-ness of Python, while keeping the performance of C.  Truly, numpy is a modern marvel.\n",
    "\n",
    "Let's see some examples of numpy's performance in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364 µs ± 20.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit array = np.random.normal(0, 1, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.55 ms ± 256 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def generate_array():\n",
    "    return [random.gauss(0, 1) for _ in range(10000)]\n",
    "\n",
    "%timeit generate_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, numpy is an _order_ of magnitude faster.  There are a lot of examples similar to this.  We'll look at just a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_one = np.random.normal(0, 1, size=10000)\n",
    "array_two = np.random.normal(0, 1, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.15 µs ± 16.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit array_one + array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_array_elements(array_one, array_two):\n",
    "    return [array_one[index] + array_two[index]\n",
    "            for index in range(len(array_one))]\n",
    "\n",
    "array_one = generate_array()\n",
    "array_two = generate_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715 µs ± 1.35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_array_elements(array_one, array_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time numpy is _2 orders_ of magnitude faster.  And the syntax was _much_ clearer.  Granted, it is less clear what we are doing, unless you know the numpy api.  Whenever you add two vectors in numpy, this adds each element together.  So beware!  You can also do multiplication just as easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_one = np.random.normal(0, 1, size=10000)\n",
    "array_two = np.random.normal(0, 1, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57 µs ± 82.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit array_one * array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_array_elements(array_one, array_two):\n",
    "    return [array_one[index] * array_two[index]\n",
    "            for index in range(len(array_one))]\n",
    "\n",
    "array_one = generate_array()\n",
    "array_two = generate_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727 µs ± 6.71 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit multiply_array_elements(array_one, array_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the orders of magnitude are similar for multiplication as they were for addition.  This is actually a _much_ bigger deal than may be obvious from these two examples.  All of linear algebra relies on these two operations.  That means linear regression, logistic regression, neural networks are all around 100 times faster implemented with numpy as compared to vanilla Python.  Of course, that is a blanket statement.  There are things you can do to make vanilla Python move faster.  And you can implement numpy poorly.  So this is a statement that needs to be taken with a grain of salt.  But still, numpy is faster for the things that matter to folks working in statistics and machine learning.  And that's just a fact.\n",
    "\n",
    "Since numpy is _so fast_.  It can actually be used as a minimal in memory database.  Here we'll go over some of the basics for querying data in numpy.  Some of the syntax here will be confusing at first, but with time and practice it will become clear.\n",
    "\n",
    "Let's look at a simple example of selecting a specific section of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3142"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.random.normal(0, 1, size=10000)\n",
    "\n",
    "len(array[array > 0.5])/len(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did a little stylizing here returning the percentage of the array over 0.5.  But basically this shows us the querying syntax.  This syntax is definitely _not_ obvious on first blush.  That said, once you get used to it, it's pretty powerful.  What's going on here is the following:\n",
    "\n",
    "the inner bit of syntax: `array > 0.5` is a boolean statement.  That is, implicitly every element of the array is checked for the condition, element of array greater than 0.5.  If the element meets the condition `True` is returned, otherwise False is returned.  Then a boolean array is passed to the array as a slice:\n",
    "\n",
    "`array[boolean statement goes here]`.\n",
    "\n",
    "Then indices where the index in question is `True` is returned.  Any indices that return `False` are ommited.  In this way, you can \"semantically slice\" your array.  To make this concrete, let's look at just the result of `array > 05`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is just an array of boolean values.  And if we counted up the number of times that resultant array has the value `True` it would equal the size of the semantically sliced array: `array[array > 0.5]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3142\n",
      "3142\n"
     ]
    }
   ],
   "source": [
    "print((array > 0.5).astype(int).sum())\n",
    "print(len(array[array > 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way I counted the number of `True`'s may be confusing, so let's look at that: \n",
    "\n",
    "By casting the `True`'s and `False`'s as type `int` we turn the `True`'s into `1`'s and the `False`'s into `0`'s. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
